{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379c09d0-9de5-4ba1-bdd9-01879f638ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from itertools import groupby\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as nnf\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import clip\n",
    "\n",
    "import numpy as np\n",
    "from os.path import join, isdir, expanduser\n",
    "from PIL import Image\n",
    "\n",
    "data_path = expanduser('~/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1aa206-1759-4cb4-abbb-0549e2c0b04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A loading: 100%|██████████| 1936/1936 [00:09<00:00, 207.91it/s]\n",
      "B loading: 100%|██████████| 1936/1936 [00:09<00:00, 202.44it/s]\n",
      "A processing: 100%|██████████| 1936/1936 [01:29<00:00, 21.62it/s]\n",
      "B processing: 100%|██████████| 1936/1936 [01:50<00:00, 17.52it/s]\n",
      "A loading: 100%|██████████| 64/64 [00:00<00:00, 207.54it/s]\n",
      "B loading: 100%|██████████| 64/64 [00:00<00:00, 205.80it/s]\n",
      "A processing: 100%|██████████| 64/64 [00:03<00:00, 17.62it/s]\n",
      "B processing: 100%|██████████| 64/64 [00:03<00:00, 19.10it/s]\n"
     ]
    }
   ],
   "source": [
    "num_images = 2000\n",
    "test_size = 64\n",
    "size = (256,256)\n",
    "\n",
    "\n",
    "A_path = [\"share\", \"construction\"]\n",
    "B_path = [\"share\", \"finished\"]\n",
    "\n",
    "A_files = os.listdir(join(data_path, *A_path))\n",
    "B_files = os.listdir(join(data_path, *B_path))\n",
    "\n",
    "\n",
    "train_A_raw = [Image.open(join(data_path, *A_path, f)).resize(size)\n",
    "          for f in tqdm(A_files[test_size:num_images], desc=\"A loading\") if f.endswith('.jpg')]\n",
    "\n",
    "train_B_raw = [Image.open(join(data_path, *B_path, f)).resize(size)\n",
    "          for f in tqdm(B_files[test_size:num_images], desc=\"B loading\") if f.endswith('.jpg')]\n",
    "\n",
    "\n",
    "trans = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.48145466, 0.4578275, 0.40821073], [0.26862954, 0.26130258, 0.27577711])\n",
    "        ])\n",
    "\n",
    "train_A = [trans(img.convert(\"RGB\")) for img in tqdm(train_A_raw, desc=\"A processing\")]\n",
    "train_B = [trans(img.convert(\"RGB\")) for img in tqdm(train_B_raw, desc=\"B processing\")]\n",
    "\n",
    "torch.save(train_A, \"A_big.pt\")\n",
    "torch.save(train_B, \"B_big.pt\")\n",
    "\n",
    "\n",
    "test_A_raw = [Image.open(join(data_path, *A_path, f)).resize(size)\n",
    "          for f in tqdm(A_files[:test_size], desc=\"A loading\") if f.endswith('.jpg')]\n",
    "\n",
    "test_B_raw = [Image.open(join(data_path, *B_path, f)).resize(size)\n",
    "          for f in tqdm(B_files[:test_size], desc=\"B loading\") if f.endswith('.jpg')]\n",
    "\n",
    "\n",
    "test_A = [trans(img.convert(\"RGB\")) for img in tqdm(test_A_raw, desc=\"A processing\")]\n",
    "test_B = [trans(img.convert(\"RGB\")) for img in tqdm(test_B_raw, desc=\"B processing\")]\n",
    "\n",
    "torch.save(test_A, \"A_test_big.pt\")\n",
    "torch.save(test_B, \"B_test_big.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b834d85-bd14-41b8-ae0f-a3178ea6b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A_raw[6] = train_A_raw[6].convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "584fd425-cce1-4f80-9459-447fd37c705f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RGB'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_A_raw[6].mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jonas_florian",
   "language": "python",
   "name": "jonas_florian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
