{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5632a38-5d60-40ac-9942-1e3808cdae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import os\n",
    "from os.path import join, isdir, expanduser\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_path = expanduser('~/datasets')\n",
    "\n",
    "# need to adapt locally\n",
    "\n",
    "raw_image_path = [\"share\", \"raw_images\"]\n",
    "construction_path = [\"share\", \"construction\"]\n",
    "finished_path = [\"share\", \"finished\"]\n",
    "\n",
    "image_files = os.listdir(join(data_path, *construction_path))\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1298c-758a-4f9d-868c-4cfc04e7d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CLIP performance for keyword sentences with already correctly separated images \n",
    "\n",
    "num_images = 10\n",
    "\n",
    "# Prepare the inputs\n",
    "raw_image_batch = [Image.open(join(data_path, *construction_path, f))\n",
    "          for f in tqdm(image_files[:num_images], desc=\"Raw Images loading\") if f.endswith('.jpg')]\n",
    "\n",
    "# image = raw_image_batch[1]\n",
    "images = raw_image_batch\n",
    "\n",
    "classes=[\"building in construction\", \"finished building\"]\n",
    "\n",
    "pp_images = [preprocess(img) for img in images]\n",
    "\n",
    "for img in pp_images:\n",
    "    image_input = img.unsqueeze(0).to(device)\n",
    "    # image_input = preprocess(images).unsqueeze(0).to(device)\n",
    "    text_inputs = torch.cat([clip.tokenize(f\"a image of a {c}\") \n",
    "                                 for c in classes]).to(device)\n",
    "\n",
    "    # Calculate features\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "        text_features = model.encode_text(text_inputs)\n",
    "\n",
    "    # Pick the top 5 most similar labels for the image\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    values, indices = similarity[0].topk(2)\n",
    "\n",
    "    # Print the result\n",
    "    print(\"\\nTop predictions:\\n\")\n",
    "    for value, index in zip(values, indices):\n",
    "        print(f\"{classes[index]}: {100 * value.item():.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ca355-a7e3-404c-925c-97fe1791100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "def save_file(path, filename):\n",
    "    if os.path.exists(join(path, filename)):\n",
    "        save_file(path, \"0\"+filename)\n",
    "    else:\n",
    "        file = open(join(path, filename), \"wb\")\n",
    "        file.write(response.content)\n",
    "        file.close()\n",
    "\n",
    "\n",
    "classes=[\"skyscraper in construction\", \"finished skyscraper\", \"construction site\"]\n",
    "\n",
    "# data = pd.read_csv(join(data_path, \"share\", \"buildingconstruction.tsv\"),\n",
    "#                    sep=\"\\t\", error_bad_lines=False)\n",
    "# data = data.rename(columns={\n",
    "#                    'http://farm4.staticflickr.com/3055/2330466409_fc8133ec39.jpg': 'image_url'})\n",
    "\n",
    "data = pd.read_csv(join(data_path, \"share\", \"skyscraper.tsv\"),\n",
    "                   sep=\"\\t\", error_bad_lines=False)\n",
    "data = data.rename(columns={\n",
    "                   'http://farm3.staticflickr.com/2384/3543591719_b5f2cf8c98.jpg': 'image_url'})\n",
    "\n",
    "# data = data.rename(columns={\n",
    "#    'http://farm3.staticflickr.com/2384/3543591719_b5f2cf8c98.jpg': 'image_url'})\n",
    "data = data['image_url']\n",
    "# print(len(data.tolist()))\n",
    "\n",
    "for i, url in enumerate(data.tolist()[0:10000]):\n",
    "    # response = requests.get(\"https://i.imgur.com/ExdKOOz.png\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except requests.exceptions.MissingSchema as err:\n",
    "        print(err)\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "    except UnidentifiedImageError:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    image_input = preprocess(img).unsqueeze(0).to(device)\n",
    "    text_inputs = torch.cat([clip.tokenize(f\"a image of a {c}\") \n",
    "                                 for c in classes]).to(device)\n",
    "\n",
    "    # Calculate features\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "        text_features = model.encode_text(text_inputs)\n",
    "\n",
    "    # Pick the top 5 most similar labels for the image\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    values, indices = similarity[0].topk(2)\n",
    "\n",
    "    # save image if it is more likely to be finished\n",
    "    if indices[0] == 1:\n",
    "        # save_file(join(data_path, *construction_path), f\"{i}.jpg\")\n",
    "        save_file(join(data_path, *finished_path), f\"{i}.jpg\")\n",
    "        \n",
    "\n",
    "        # Print the result\n",
    "        print(\"\\nTop predictions:\\n\")\n",
    "        for value, index in zip(values, indices):\n",
    "            print(f\"{classes[index]}: {100 * value.item():.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2941f137-e7f8-4794-a27f-3afde074781b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.available_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895efb41-3420-4ad3-93da-73440d76b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "url = 'https://farm4.staticflickr.com/3055/2330466409_fc8133ec39.jpg'\n",
    "response = requests.get(url)\n",
    "file = open(join(data_path, *construction_path, f\"{1}.jpg\"), \"wb\")\n",
    "file.write(response.content)\n",
    "file.close()\n",
    "\n",
    "# img = Image.open(BytesIO(response.content))\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66903aac-5dc5-4ff9-a922-e22b6ec58a6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19394/1276659192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mconstruction_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "image_files = os.listdir(join(data_path, *construction_path))\n",
    "for i in image_files:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f83140-6160-4dc0-9da9-f80056855c77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Training a Clip Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e98be792-1b1e-4e7b-965b-90bbbc08af78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f8bafb22f90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82a82cd-1180-4921-a049-0dceea301370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "data_path = expanduser('~/datasets')\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time, sleep\n",
    "\n",
    "path_training_img_path = [\"share\", \"clip_training_construction\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89751053-96dd-4748-889b-56637095606f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_list = ['building in construction', 'finished building', 'construction site', 'tree', 'car', 'city', 'cat', 'dog']\n",
    "image_files = [img for img in os.listdir(join(data_path, *path_training_img_path)) if img.endswith('.jpg')]\n",
    "\n",
    "len(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edbc68-f231-4a9b-b9f6-7087e983ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO ADD :\n",
    "# Gradient Checkpointing\n",
    "# Filter out bias from weight decay\n",
    "# Decaying learning rate with cosine schedule\n",
    "# Half-precision Adam statistics\n",
    "# Half-precision stochastically rounded text encoder weights were used\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # If using GPU then use mixed precision training.\n",
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "\n",
    "class image_title_dataset(Dataset):\n",
    "    def __init__(self, list_image,list_txt,img_path=join(data_path, *path_training_img_path)):\n",
    "\n",
    "        self.list_image = list_image\n",
    "        self.title  = clip.tokenize(list_txt) #you can tokenize everything at once in here(slow at the beginning), or tokenize it in the training loop.\n",
    "        self.img_path = img_path\n",
    "    def __len__(self):\n",
    "        return len(self.list_image)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(f\"idx is {idx}\")\n",
    "        image = preprocess(Image.open(join(self.img_path, self.list_image[idx]))) # Image from PIL module\n",
    "        title = self.title[idx]\n",
    "        return image,title\n",
    "\n",
    "# use your own data\n",
    "# path_training_img_path = [\"share\", \"clip_training_construction\"]\n",
    "\n",
    "image_files = [img for img in os.listdir(join(data_path, *path_training_img_path)) if img.endswith('.jpg')]\n",
    "prompt_list = ['building under construction', 'finished building', 'construction site', 'tree', 'car', 'city', 'cat', 'dog']\n",
    "prompt_list = [f'a photo of a {img_class}' for img_class in prompt_list]\n",
    "print(prompt_list)\n",
    "# list_image_path = ['folder/image1.jpg','folder2/image2.jpg'] \n",
    "# list_txt = ['description for image1.jpg' , 'description for image2.jpg']\n",
    "dataset = image_title_dataset(image_files,prompt_list)\n",
    "train_dataloader = DataLoader(dataset,batch_size = BATCH_SIZE, shuffle=True) #Define your own dataloader\n",
    "\n",
    "#https://github.com/openai/CLIP/issues/57\n",
    "def convert_models_to_fp32(model): \n",
    "    for p in model.parameters(): \n",
    "        p.data = p.data.float() \n",
    "        p.grad.data = p.grad.data.float() \n",
    "\n",
    "\n",
    "# if device == \"cpu\":\n",
    "#   model.float()\n",
    "# else :\n",
    "#   clip.model.convert_weights(model) # Actually this line is unnecessary since clip by default already on float16\n",
    "\n",
    "epochs = 60\n",
    "\n",
    "#define image to optimize over\n",
    "\n",
    "image_file = preprocess(Image.open(join(data_path, *path_training_img_path, image_files[0])))\n",
    "\n",
    "loss_img = nn.CrossEntropyLoss()\n",
    "loss_txt = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam([image_file], lr=5e-5,betas=(0.9,0.98),eps=1e-6,weight_decay=0.2) #Params used from paper, the lr is smaller, more safe for fine tuning to new dataset\n",
    "# optimizer = optim.Adam(model.parameters(), lr=5e-5,betas=(0.9,0.98),eps=1e-6,weight_decay=0.2) #Params used from paper, the lr is smaller, more safe for fine tuning to new dataset\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images,texts = batch \n",
    "\n",
    "        images= images.to(device)\n",
    "        texts = texts.to(device)\n",
    "        # print(f\"type {type(texts)}\")\n",
    "        # print(f\"type {texts}\")\n",
    "        logits_per_image, logits_per_text = model(images, texts)\n",
    "        \n",
    "        # ground_truth = torch.arange(len(images),dtype=torch.long,device=device)\n",
    "        ground_truth = torch.tensor([0], dtype=torch.long).to(device)\n",
    "        # ground_truth = torch.flatten(ground_truth.expand(8,1).to(device))\n",
    "        \n",
    "        \n",
    "        total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
    "        epoch_loss.append(total_loss)\n",
    "        \n",
    "        if epoch % 5 == 4:    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, (sum(epoch_loss) / len(epoch_loss))))\n",
    "        \n",
    "        total_loss.backward()\n",
    "        if device == \"cpu\":\n",
    "            optimizer.step()\n",
    "        else: \n",
    "            convert_models_to_fp32(model)\n",
    "            optimizer.step()\n",
    "            # convert back to fp16\n",
    "            clip.model.convert_weights(model)\n",
    "    train_loss.append((sum(epoch_loss) / len(epoch_loss)).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1323a1bd-392a-428b-a6a4-3e398f38f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a photo of a building under construction', 'a photo of a finished building', 'a photo of a construction site', 'a photo of a tree', 'a photo of a car', 'a photo of a city', 'a photo of a cat', 'a photo of a dog']\n",
      "[10,     1] loss: 0.010\n",
      "[20,     1] loss: 0.005\n",
      "[30,     1] loss: 0.004\n",
      "[40,     1] loss: 0.003\n",
      "[50,     1] loss: 0.002\n",
      "[60,     1] loss: 0.002\n",
      "[70,     1] loss: 0.001\n",
      "[80,     1] loss: 0.001\n",
      "[90,     1] loss: 0.001\n",
      "[100,     1] loss: 0.001\n",
      "[110,     1] loss: 0.001\n",
      "[120,     1] loss: 0.001\n",
      "[130,     1] loss: 0.001\n",
      "[140,     1] loss: 0.001\n",
      "[150,     1] loss: 0.001\n",
      "[160,     1] loss: 0.000\n",
      "[170,     1] loss: 0.000\n",
      "[180,     1] loss: 0.000\n",
      "[190,     1] loss: 0.000\n",
      "[200,     1] loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Train over image\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # If using GPU then use mixed precision training.\n",
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "\n",
    "image_files = [img for img in os.listdir(join(data_path, *path_training_img_path)) if img.endswith('.jpg')]\n",
    "prompt_list = ['building under construction', 'finished building', 'construction site', 'tree', 'car', 'city', 'cat', 'dog']\n",
    "prompt_list = [f'a photo of a {img_class}' for img_class in prompt_list]\n",
    "print(prompt_list)\n",
    "\n",
    "def saver(clip, exp_id = \"\"):\n",
    "    now = datetime.now()\n",
    "    time = now.strftime(\"%m.%d._%H:%M\")\n",
    "    \n",
    "    path = os.path.join(\"saves\", exp_id, time)\n",
    "    \n",
    "    os.makedirs(path)\n",
    "    \n",
    "    torch.save(clip.state_dict(), os.path.join(path, \"clip\" + \".pth\"))\n",
    "\n",
    "def convert_models_to_fp32(model): \n",
    "    for p in model.parameters(): \n",
    "        p.data = p.data.float() \n",
    "        # p.grad.data = p.grad.data.float() \n",
    "\n",
    "epochs = 200\n",
    "\n",
    "#define image to optimize over\n",
    "image_file = preprocess(Image.open(join(data_path, *path_training_img_path, image_files[0])))\n",
    "# pre_img = image_file.clone()\n",
    "\n",
    "loss_img = nn.CrossEntropyLoss()\n",
    "loss_txt = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "image_file.requires_grad = True\n",
    "\n",
    "# optimizer = optim.Adam([image_file], lr=5e-3,betas=(0.9,0.98),eps=1e-6,weight_decay=0.2) #Params used from paper, the lr is smaller, more safe for fine tuning to new dataset\n",
    "optimizer = optim.Adam([image_file], lr=0.001)\n",
    "\n",
    "last_save = time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    images,texts = image_file,prompt_list \n",
    "\n",
    "    images= images.unsqueeze(0).to(device)\n",
    "    texts = clip.tokenize(texts).to(device)\n",
    "\n",
    "    logits_per_image, logits_per_text = model(images, texts)\n",
    "\n",
    "    ground_truth = torch.tensor([0], dtype=torch.long).to(device)\n",
    "    ground_truth_text = torch.flatten(ground_truth.expand(8,1).to(device))\n",
    "    \n",
    "    total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth_text))/2\n",
    "    epoch_loss.append(total_loss)\n",
    "\n",
    "    if epoch % 10 == 9:    \n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, (sum(epoch_loss) / len(epoch_loss))))\n",
    "\n",
    "    total_loss.backward()\n",
    "    if device == \"cpu\":\n",
    "        optimizer.step()\n",
    "    else: \n",
    "        convert_models_to_fp32(model)\n",
    "        optimizer.step()\n",
    "        # convert back to fp16\n",
    "        clip.model.convert_weights(model)\n",
    "    # save model after every 100 epochs\n",
    "    \n",
    "    if time() - last_save >= 300:\n",
    "        last_save = time()\n",
    "        saver(model, \"01_Clip\")\n",
    "\n",
    "    \n",
    "\n",
    "    train_loss.append((sum(epoch_loss) / len(epoch_loss)).detach().cpu().numpy())\n",
    "saver(model, \"01_Clip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "12e64b5f-7a4f-40bc-8dbc-6574ed264a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training Loss\")\n",
    "# plt.plot(val_losses,label=\"val\")\n",
    "plt.plot(train_loss,label=\"train\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67180cc4-7b11-457d-b0f2-f109a01dfbb6",
   "metadata": {},
   "source": [
    "Compare Performance with untrained Clip model on dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "322440b9-6e3e-4a85-85d9-f486f2410628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construction_path = [\"share\", \"Florian_Jonas_construction\"]\n",
    "finished_path = [\"share\", \"Florian_Jonas_finished\"]\n",
    "\n",
    "image_files = os.listdir(join(data_path, *construction_path))\n",
    "\n",
    "untrained_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "trained_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "trained_model_path = os.path.join(\"saves\", \"01_Clip\", \"06.22._00:35\")\n",
    "trained_model.load_state_dict(torch.load(os.path.join(trained_model_path, \"clip\" + \".pth\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c64a3087-3101-40f5-b1f8-a1e8db4246e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Raw Images loading: 100%|█████████████████████| 50/50 [00:00<00:00, 3684.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "construction site: 12.50%\n",
      "finished building: 12.50%\n",
      "building under construction: 12.50%\n",
      "Top-One Accuracy of not fine-tuned Clip: 0.0% \n",
      "Top-One Accuracy of fine-tuned Clip: 0.0% \n"
     ]
    }
   ],
   "source": [
    "num_images = 50\n",
    "\n",
    "# Prepare the inputs\n",
    "raw_image_batch = [Image.open(join(data_path, *construction_path, f))\n",
    "          for f in tqdm(image_files[:num_images], desc=\"Raw Images loading\") if f.endswith('.jpg')]\n",
    "\n",
    "images = raw_image_batch\n",
    "\n",
    "classes = ['building under construction', 'finished building', 'construction site', 'tree', 'car', 'city', 'cat', 'dog']\n",
    "\n",
    "pp_images = [preprocess(img) for img in images]\n",
    "\n",
    "top_one_accuracy_untrained_model = 0\n",
    "top_one_accuracy_trained_model = 0\n",
    "total = 1\n",
    "\n",
    "for img in pp_images:\n",
    "    image_input = img.unsqueeze(0).to(device)\n",
    "    # image_input = preprocess(images).unsqueeze(0).to(device)\n",
    "    text_inputs = torch.cat([clip.tokenize(f\"a image of a {classes}\") \n",
    "                                 for c in classes]).to(device)\n",
    "    \n",
    "    # untrained model:\n",
    "    \n",
    "    # Calculate features\n",
    "    with torch.no_grad():\n",
    "        image_features = untrained_model.encode_image(image_input)\n",
    "        text_features = untrained_model.encode_text(text_inputs)\n",
    "\n",
    "    # Pick the top 3 most similar labels for the image\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    values, indices = similarity[0].topk(3)\n",
    "\n",
    "    if (indices[0] == 0):\n",
    "        top_one_accuracy_untrained_model += 1\n",
    "    for value, index in zip(values,indices): \n",
    "        print(f\"{classes[index]}: {100 * value.item():.2f}%\")\n",
    "        \n",
    "        \n",
    "    # trained model:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_features = trained_model.encode_image(image_input)\n",
    "        text_features = trained_model.encode_text(text_inputs)\n",
    "\n",
    "    # Pick the top 3 most similar labels for the image\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    values, indices = similarity[0].topk(3)\n",
    "\n",
    "    if (indices[0] == 0):\n",
    "        top_one_accuracy_trained_model += 1\n",
    "    total += 1\n",
    "    for value, index in zip(values,indices): \n",
    "        print(f\"{classes[index]}: {100 * value.item():.2f}%\")\n",
    "\n",
    "print(f\"Top-One Accuracy of not fine-tuned Clip: {(top_one_accuracy_untrained_model / total) * 100}% \")\n",
    "print(f\"Top-One Accuracy of fine-tuned Clip: {(top_one_accuracy_trained_model / total) * 100}% \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832b71b-c9b5-4b3f-b1fe-9159e1b8fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,5))\n",
    "# plt.title(\"Testing Accuarcy\")\n",
    "# # plt.plot(val_losses,label=\"val\")\n",
    "# plt.plot(train_loss,label=\"train\")\n",
    "# plt.xlabel(\"epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0b4c7bbe-856c-47f8-b0f4-8c2a1ee32eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a photo of a cat', 'a photo of a building under construction', 'a photo of a dog', 'a photo of a skyscraper']\n",
      "[5,     1] loss: 0.027\n",
      "[5,     2] loss: 0.017\n",
      "[10,     1] loss: 0.013\n",
      "[10,     2] loss: 0.051\n",
      "[15,     1] loss: 0.644\n",
      "[15,     2] loss: 0.374\n",
      "[20,     1] loss: 0.000\n",
      "[20,     2] loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Test training function for simplistic example\n",
    "path_training_img_path = [\"share\", \"clip_generic_example\"]\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # If using GPU then use mixed precision training.\n",
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "\n",
    "class image_title_dataset(Dataset):\n",
    "    def __init__(self, list_image,list_txt,img_path=join(data_path, *path_training_img_path)):\n",
    "\n",
    "        self.list_image = list_image\n",
    "        self.title  = clip.tokenize(list_txt) #you can tokenize everything at once in here(slow at the beginning), or tokenize it in the training loop.\n",
    "        self.img_path = img_path\n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(f\"idx is {idx}\")\n",
    "        image = preprocess(Image.open(join(self.img_path, self.list_image[idx]))) # Image from PIL module\n",
    "        title = self.title[idx]\n",
    "        return image,title\n",
    "\n",
    "image_files = [img for img in os.listdir(join(data_path, *path_training_img_path)) if img.endswith('.jpg')]\n",
    "prompt_list = ['cat', 'building under construction', 'dog', 'skyscraper']\n",
    "prompt_list = [f'a photo of a {img_class}' for img_class in prompt_list]\n",
    "print(prompt_list)\n",
    "\n",
    "dataset = image_title_dataset(image_files,prompt_list)\n",
    "train_dataloader = DataLoader(dataset,batch_size = BATCH_SIZE, shuffle=True) #Define your own dataloader\n",
    "\n",
    "#https://github.com/openai/CLIP/issues/57\n",
    "def convert_models_to_fp32(model): \n",
    "    for p in model.parameters(): \n",
    "        p.data = p.data.float() \n",
    "        p.grad.data = p.grad.data.float() \n",
    "\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "loss_img = nn.CrossEntropyLoss()\n",
    "loss_txt = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5,betas=(0.9,0.98),eps=1e-6,weight_decay=0.2) #Params used from paper, the lr is smaller, more safe for fine tuning to new dataset\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images,texts = batch \n",
    "\n",
    "        images= images.to(device)\n",
    "        texts = texts.to(device)\n",
    "\n",
    "        logits_per_image, logits_per_text = model(images, texts)\n",
    "        \n",
    "        # ground_truth = torch.arange(len(images),dtype=torch.long,device=device)\n",
    "        ground_truth = torch.arange(len(images), dtype=torch.long, device=device)\n",
    "        # ground_truth = torch.flatten(ground_truth.expand(8,1).to(device))\n",
    "        \n",
    "        \n",
    "        total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
    "        epoch_loss.append(total_loss)\n",
    "        \n",
    "        if epoch % 10 == 9:    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, (sum(epoch_loss) / len(epoch_loss))))\n",
    "        \n",
    "        total_loss.backward()\n",
    "        if device == \"cpu\":\n",
    "            optimizer.step()\n",
    "        else: \n",
    "            convert_models_to_fp32(model)\n",
    "            optimizer.step()\n",
    "            # convert back to fp16\n",
    "            clip.model.convert_weights(model)\n",
    "\n",
    "    train_loss.append((sum(epoch_loss) / len(epoch_loss)).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a2df8b9-fcb4-4a67-b188-07a0d08fffc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training Loss\")\n",
    "# plt.plot(val_losses,label=\"val\")\n",
    "plt.plot(train_loss,label=\"train\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "122274ed-beb2-43ec-876d-e751dfecddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss_img = nn.CrossEntropyLoss()\n",
    "# t1 = torch.rand(4, 4,dtype=torch.float64)\n",
    "# t2 = torch.rand(4,1)\n",
    "# t2 = t2.type(torch.LongTensor)\n",
    "\n",
    "t2 = torch.tensor([0], dtype=torch.long)\n",
    "t2 = t2.expand(8,1)\n",
    "torch.flatten(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735100dc-0835-4e8c-a3f8-1c303a2281e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if epoch % 100 == 99:  \n",
    "    torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': sum(epoch_loss) / len(epoch_loss),\n",
    "    }, f\"model_checkpoint/model_10.pt\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d48563-39ee-4593-af8b-9d8697d101cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "checkpoint = torch.load(\"model_checkpoint/model_10.pt\")\n",
    "\n",
    "# Use these 3 lines if you use default model setting(not training setting) of the clip. For example, if you set context_length to 100 since your string is very long during training, then assign 100 to checkpoint['model_state_dict'][\"context_length\"] \n",
    "checkpoint['model_state_dict'][\"input_resolution\"] = model.input_resolution #default is 224\n",
    "checkpoint['model_state_dict'][\"context_length\"] = model.context_length # default is 77\n",
    "checkpoint['model_state_dict'][\"vocab_size\"] = model.vocab_size \n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0e504c60-e947-4138-bf65-2a57350ea72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for expected number of images\n",
    "path_training_img_path = [\"share\", \"clip_training_construction\"]\n",
    "\n",
    "image_files = os.listdir(join(data_path, *path_training_img_path))\n",
    "only_img = [i for i in image_files if i.endswith('jpg')]\n",
    "len(only_img)\n",
    "# for img in only_img:\n",
    "    # os.rename(join(data_path,*path, img), join(data_path,*path,'construction_' + img[:-17] + '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8fe78-aa1a-46de-863a-4c805967f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if performance has improved with fine-tuned model:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
